# VINCE Plugin Progress Tracker
# Last updated: 2026-02-03 (Supabase dual-write + ML training on Eliza Cloud, no redeploy)
# Update this file after every feature completion or session end.

================================================================================
COMPLETED
================================================================================

## Core Architecture ‚úÖ
- Plugin structure (index.ts) with 27 services, 20 actions, 2 providers, 1 evaluator
- Fallback service pattern (external plugins ‚Üí built-in API clients)
- ASCII dashboard on startup with live market prices
- Service source tracking (external vs fallback logging)

## Services - Data Sources (18 services) ‚úÖ
- VinceCoinGlassService - L/S ratio, funding, OI, fear/greed
- VinceCoinGeckoService - Exchange health, liquidity, prices
- VinceMarketDataService - Enriched context (RSI, volatility, regime)
- VinceSignalAggregatorService - Weighted voting across 15+ sources
- VinceTopTradersService - Whale wallet tracking via Hyperliquid
- VinceNewsSentimentService - MandoMinutes sentiment
- VinceDexScreenerService - Hot memes on SOLANA + BASE
- VinceMeteoraService - LP pool discovery for DCA strategy
- VinceNFTFloorService - Floor tracking for ~12 curated collections
- VinceLifestyleService - Daily suggestions based on day of week
- VinceDeribitService - Options IV, Greeks, strikes
- VinceNansenService - Smart money (100 credits)
- VinceSanbaseService - On-chain analytics (1K/mo)
- VinceBinanceService - Top traders, taker flow
- VinceBinanceLiquidationService - Liquidation data
- VinceMarketRegimeService - Trending/ranging/choppy detection
- VinceHIP3Service - Stocks, commodities, indices (34 assets)
- VinceWatchlistService - Early detection watchlist
- VinceAlertService - Price and signal alerts

## Services - Paper Trading Bot (5 services) ‚úÖ
- VincePaperTradingService - Bot orchestration
- VincePositionManagerService - Position tracking
- VinceRiskManagerService - Circuit breakers, daily loss limits
- VinceTradeJournalService - Trade history
- VinceGoalTrackerService - $420/day, $10K/month KPIs

## Services - Self-Improving Architecture (2 services) ‚úÖ
- VinceParameterTunerService - Bayesian parameter optimization
- VinceImprovementJournalService - Structured improvement suggestions

## Services - ML Enhancement Layer (4 services) ‚úÖ
- VinceFeatureStoreService - 40+ features per trade (JSONL)
- VinceWeightBanditService - Thompson Sampling for signal weights
- VinceSignalSimilarityService - k-NN on embeddings
- VinceMLInferenceService - ONNX model inference

## Fallback Services (7 fallbacks) ‚úÖ
- deribit.fallback.ts - Direct Deribit API client
- hyperliquid.fallback.ts - Direct Hyperliquid API client
- opensea.fallback.ts - OpenSea NFT floor fallback
- nansen.fallback.ts - Nansen API fallback
- xai.fallback.ts - XAI/Grok API fallback
- browser.fallback.ts - Browser automation fallback
- puppeteer.browser.ts - Puppeteer-based browser

## Actions - Focus Areas (11 actions) ‚úÖ
- vinceGmAction - Morning briefing
- vinceAlohaAction - Evening summary
- vinceOptionsAction - Covered calls / secured puts
- vincePerpsAction - Long/short signals
- vinceMemesAction - Hot memes scanner
- vinceAirdropsAction - Airdrop tracking
- vinceLifestyleAction - Daily suggestions
- vinceNftFloorAction - NFT floor analysis
- vinceIntelAction - Combined intelligence
- vinceNewsAction - MandoMinutes news
- vinceHIP3Action - TradFi assets (gold, NVDA, SPX)

## Actions - Paper Trading Bot (4 actions) ‚úÖ
- vinceBotStatusAction - Portfolio status
- vinceBotPauseAction - Pause/resume bot
- vinceWhyTradeAction - Explain trade decision
- vinceBotAction - Execute trade

## Actions - Utilities (5 actions) ‚úÖ
- vinceUploadAction - Knowledge upload; URLs/YouTube via [Ikigai Labs summarize](https://github.com/IkigaiLabsETH/summarize) (bunx), saves to knowledge/<category>/ ‚Äî keeps improving our knowledge base from any URL or video. Optional: VINCE_UPLOAD_EXTRACT_ONLY=true for extract-only (no LLM; saves cost).
- vinceGrokExpertAction - Daily pulse + research suggestions
- vinceMemeDeepDiveAction - Deep dive into specific meme
- vinceWatchlistAction - Manage watchlist
- vinceAlertsAction - Manage alerts

## Providers (2 providers) ‚úÖ
- vinceContextProvider - Aggregated market context
- trenchKnowledgeProvider - RAG for meme trading knowledge

## Evaluators (1 evaluator) ‚úÖ
- tradePerformanceEvaluator - Track signal source performance

## Tasks (1 task) ‚úÖ
- grokExpert.tasks.ts - Daily Grok research task

## Tests ‚úÖ
- Unit tests: actions (4 files), bullBearCase, standalone
- Integration tests: knowledge, hip3-verify, hyperliquid-verify
- E2E tests: realData, knowledgeQuality
- Test utilities: test-utils.ts, knowledge-utils.ts

## Documentation ‚úÖ
- WHAT.md - Purpose and philosophy
- WHY.md - Framework decisions (ElizaOS vs ClawdBot)
- HOW.md - Development guide
- CLAUDE.md - AI operating manual
- START.md - Complete vibe coding manifesto
- README.md - Project overview
- progress.txt - This file

## Configuration ‚úÖ
- dynamicConfig.ts - Tunable parameters
- paperTradingDefaults.ts - Bot defaults
- targetAssets.ts - BTC, ETH, SOL, HYPE + 34 HIP-3
- memes.constants.ts - 50+ tracked meme tokens

## Paper trading algo: data leverage + tests (current) ‚úÖ
- We can claim the paper trading algo was improved by: (1) wiring more market data into live logic and feature store (order-book imbalance, price vs SMA20, funding 8h delta, DVOL); (2) book-imbalance filter (reject long when book favors sellers, short when favors buyers); (3) confidence boosts when trend/SMA20 and funding reversal align; (4) DVOL-based size cap; (5) unit tests for extended-snapshot logic (23 tests, 100% coverage). ML pipeline and train_models.py include these features; retrain + deploy to have models use them. We do not yet claim improved P&L or win rate‚Äîthat requires backtest or live results over time.

## Essential bug fix: Stale P&L / uPNL (2026-02-03) ‚úÖ
- Bug: Paper bot reported positions as "underwater" with stale unrealized P&L (e.g. -$40) while the market had already moved (e.g. BTC short from $75,872 at $75K was actually profitable). Strategy and entry were correct; only the displayed P&L was wrong.
- Root cause: (1) Unrealized P&L is computed from mark price in VincePositionManager; mark price is updated every 30s by the paper loop via marketData.getEnrichedContext(asset) ‚Üí ctx.currentPrice. (2) currentPrice comes from CoinGecko (coingeckoService.getPrice). (3) getEnrichedContext() refreshed CoinGlass but never called coingeckoService.refreshData(), so it always read from cache. (4) CoinGecko cache was only refreshed at service init and in a few other paths; TTL was 5 minutes. Result: P&L could be up to 5 minutes stale during fast moves.
- Fixes applied: (1) marketData.service.ts: call coingeckoService.refreshData() before getPrice(asset) in getEnrichedContext() so the paper loop gets a chance to refresh. (2) coingecko.service.ts: reduce CACHE_TTL_MS from 5 min to 1 min so the 30s loop gets fresher prices without hammering the API. (3) vinceContext.provider.ts: when user asks for bot status/portfolio/uPNL, call paperTrading.refreshMarkPrices() before building context so the reply shows current P&L. (4) vincePaperTrading.service.ts: added public refreshMarkPrices() for on-demand refresh. (5) Trigger words for status refresh include "upnl" and "pnl".
- Doc: STALE_PNL_INVESTIGATION.md in plugin-vince root summarizes root cause and fixes.

## Knowledge ingestion playbook (summarize) ‚úÖ
- UPLOAD in chat: "upload: <url>" or YouTube link ‚Üí summarize CLI (bunx) ‚Üí knowledge/<category>/.
- Batch: scripts/ingest-urls.ts ‚Äî URLs from args or --file urls.txt; --extract (web URLs get --format md), --youtube, --slides/--slides-ocr, --length long|xl|xxl|medium|short; writes to knowledge/ with same category heuristics as UPLOAD.
- Extract-only: VINCE_UPLOAD_EXTRACT_ONLY=true makes UPLOAD use summarize --extract only (no LLM; cheaper); web URLs get --format md.
- YouTube slides: VINCE_UPLOAD_YOUTUBE_SLIDES=true (and VINCE_UPLOAD_YOUTUBE_SLIDES_OCR for OCR); or --slides/--slides-ocr in batch script. Slides written to knowledge/.slides/ (gitignored).
- Summary length: VINCE_UPLOAD_SUMMARY_LENGTH=long|xl|xxl|medium|short; or --length in batch script.
- Firecrawl: VINCE_UPLOAD_FIRECRAWL=auto|always for web URLs (FIRECRAWL_API_KEY); or --firecrawl in batch script.
- Language: VINCE_UPLOAD_LANG=<code> for --lang; or --lang in batch script.
- Timeout: Upload and batch pass --timeout to summarize CLI so it doesn't exit early.
- Local files: ingest-urls accepts local paths (PDF, audio, video, text) as well as URLs; --file can list mixed URLs and paths.
- UPLOAD robustness: runSummarizeCli retries once on non-zero exit; on failure the reply includes a short stderr snippet from summarize for debugging. Saved files from URL/YouTube get frontmatter ingestedWith: summarize (chat uploads: vince-upload).
- Batch script: --concurrency <n> (default 3) runs up to n jobs in parallel; at end the script lists failed inputs. Written files get ingestedWith: ingest-urls in frontmatter.
- Docs: scripts/README.md has "Knowledge ingestion playbook", ingest-urls usage, and a Troubleshooting subsection (API keys, timeout, too little content, rate limits). PDF/podcast URLs supported by summarize (same flow).

## Why knowledge is essential for VINCE
- **Data vs methodology:** Actions and services supply *current* data (prices, funding, OI, signals). The knowledge base supplies *how to think*‚Äîframeworks, methodologies, and strategic patterns. Without knowledge, VINCE would only echo numbers; with it, VINCE interprets data through proven lenses (e.g. funding ‚Üí strike distance, TVL red flags, meme lifecycle, options skew).
- **RAG in every turn:** trenchKnowledgeProvider pulls relevant knowledge into context so the LLM can reference methodologies when answering OPTIONS, PERPS, MEMES, LIFESTYLE, etc. That makes responses analytical instead of generic.
- **Single source of truth for ‚Äúhow‚Äù:** Knowledge holds strike-selection frameworks, risk-assessment patterns, and domain-specific heuristics. Live APIs hold ‚Äúwhat is happening now.‚Äù Keeping them separate (see knowledge/KNOWLEDGE-USAGE-GUIDELINES.md) avoids treating outdated numbers as current and keeps the agent focused on applying frameworks to live data.
- **Continuous improvement:** UPLOAD + summarize + batch ingest let the team (and the user) grow knowledge from URLs, YouTube, PDFs, and podcasts. Every ingested essay or video expands the frameworks VINCE can draw on, so the agent gets smarter as the knowledge/ folder grows.
- **Concrete ‚Äúwithout vs with‚Äù:** Without knowledge: ‚ÄúBTC funding is 0.02%.‚Äù With knowledge: ‚ÄúFunding is 0.02%‚Äîknowledge says extreme positive funding often precedes mean reversion; combined with current L/S ratio, that suggests caution on new longs.‚Äù Same number, added interpretation. For OPTIONS, knowledge provides the HYPE wheel and strike-distance logic; for MEMES, lifecycle and TVL/MCap frameworks; for LIFESTYLE, the-good-life selection criteria. That‚Äôs what turns a data dashboard into a reasoning teammate.
- **Differentiation:** A generic market API returns numbers. VINCE returns numbers *plus* methodology-backed interpretation because context includes both live data (vinceContextProvider) and curated frameworks (trenchKnowledgeProvider). The paper bot‚Äôs ML handles *when* and *how much*; knowledge helps the LLM explain *why* and *what to watch next* in plain language.

## TypeScript / type alignment (2026-02-03) ‚úÖ
- Fixed 13 TS errors in vincePaperTrading.service.ts and related types. Position: added realizedPnlPct to paperTrading.ts; VincePositionManager.closePosition now sets position.realizedPnlPct when closing. recordExecution: call fixed to recordExecution(decisionId, position, additionalDetails) with valid TradeExecutionFeatures (entryAtrPct, streakMultiplier, positionSizePct); removed invalid fillPrice. recordOutcome: outcome object aligned with feature store (exitPrice, realizedPnl, realizedPnlPct, exitReason, holdingPeriodMs, etc.); use position.closedAt/openedAt for holdingPeriodMs; removed profitable/durationMs. VinceMarketRegimeService: added getCurrentRegime(asset?) returning { marketRegime, volatilityRegime? }; signalAggregator and paper trading use await getCurrentRegime(asset). AggregatedTradeSignal: added toAggregatedTradeSignal(signal) in paper trading to build full type (conflictingCount, signals, reasons, sourceBreakdown) from AggregatedSignal; all logSignalRejection calls use it instead of unsafe casts. Build completes cleanly.

## Algo ML Improvements ‚úÖ
- ALGO_ML_IMPROVEMENTS.md: roadmap for using ML more (position sizing, TP/SL wiring, block low ML quality, improvement report, similarity filter, bandit feedback). Implemented: ML position sizing in paper trading (evaluateAndTrade) ‚Äì base size multiplied by predictPositionSize (0.5‚Äì2x) using signal quality, strength, confidence, volatility regime, drawdown, recent win rate, streak.
- ONNX export: train_models.py uses onnxmltools (not skl2onnx) for XGBoost ‚Üí ONNX; booster feature names temporarily set to f0, f1, ‚Ä¶ for converter compatibility. All four models (signal_quality, position_sizing, tp_optimizer, sl_optimizer) export to .onnx when pip3 install onnx onnxmltools. Docs/scripts use pip3 (Mac).
- Similarity "avoid" hard filter: in evaluateAndTrade(), when mlSimilarityPrediction.recommendation === "avoid", trade is skipped (with log) before validation. ALGO_ML_IMPROVEMENTS #5 done.
- Bandit outcome feedback: on open, contributingSources (source names from signal.sourceBreakdown) stored in position.metadata.contributingSources; on close, weightBandit.recordOutcome({ sources, profitable, pnlPct }) with those names so Thompson Sampling arms get PnL-weighted updates. ALGO_ML_IMPROVEMENTS #6 done.
- ALGO_ML_IMPROVEMENTS.md: added "Further ML flow improvements" (training labels, calibration, retrain triggers, feature alignment, A/B shadow mode).

## Fetch Performance (Timeouts + Parallelization) ‚úÖ
- Coinglass: 10s timeout on every fetch; refreshData() runs BTC/ETH/SOL + Fear/Greed in parallel; per-asset OI/funding/Binance L/S in parallel; fetchFreeData() runs price/funding/LS/OI in one Promise.all.
- Signal aggregator: SOURCE_FETCH_TIMEOUT_MS (12s) and withTimeout(ms, label, promise) so one slow source returns null and does not block. Phase 1: Binance, Deribit IV, MarketData, Sanbase, Hyperliquid (options pulse + cross-venue), Deribit comprehensive + DVOL fetched in a single Promise.all; sections 3‚Äì10 use pre-fetched results. Phase 2: getTakerVolume, getRSIAdjustment, getOpenWindowInfo wrapped in withTimeout. getAllSignals() uses Promise.all(assets.map(getSignal)) so multi-asset aggregation runs in parallel.

## ML Learning State ‚úÖ
- Feature store: 21+ feature/synthetic files in .elizadb/vince-paper-bot/features (features_*.jsonl, synthetic_*.jsonl). 1250+ completed trades for training.
- Synthetic data: generate_synthetic_features.py supports --count, --output, --append (timestamps continue), --win-rate, --seed. train_models.py loads all features_*.jsonl and synthetic_*.jsonl from --data dir.
- ONNX: Script exports .onnx when onnxmltools installed; joblib backups and improvement_report.md always written. Run: python3 ‚Ä¶/train_models.py --data .elizadb/vince-paper-bot/features --output .elizadb/vince-paper-bot/models --min-samples 90.
- Tests: test_train_models.py (6 tests) and generate_synthetic_features.py verified; pytest optional.

## ML on Eliza Cloud ‚úÖ
- Why Cloud had no ML: .elizadb/ is gitignored, so the deploy image never contained ONNX files; the bot fell back to rule-based signal quality, sizing, and TP/SL.
- **Option A ‚Äì Training on Cloud (no extra redeploy):** With Supabase configured, training runs **in the container** and models **persist across redeploys**.
  - Dockerfile: Python3 + pip + pip install -r scripts/requirements.txt (xgboost, onnxmltools, etc.) so TRAIN_ONNX_WHEN_READY can run train_models.py in the container.
  - One-time: Create Supabase Storage bucket **vince-ml-models** (Dashboard ‚Üí Storage ‚Üí New bucket ‚Üí name: vince-ml-models, private). See DEPLOY.md ¬ß "One-time: Create the vince-ml-models bucket".
  - After training: task uploads .onnx + training_metadata.json to vince-ml-models (supabaseMlModels.ts), then calls ML service reloadModels() so new models apply without restart.
  - On (re)deploy: ML Inference Service downloads from vince-ml-models if local models dir is empty, then loads. So no $15 redeploy needed to get new models.
  - Utils: src/plugins/plugin-vince/src/utils/supabaseMlModels.ts (getSupabaseClient, uploadModelsToSupabase, downloadModelsFromSupabase).
- **Option B ‚Äì Ship models in repo:** Copy trained .onnx + training_metadata.json into src/plugins/plugin-vince/models/, commit, deploy. Dockerfile copies that folder into .elizadb/vince-paper-bot/models/ at build time. See plugin-vince/models/README.md.
- Docs: DEPLOY.md "ML training on Eliza Cloud" and "One-time: Create the vince-ml-models bucket"; FEATURE-STORE.md ¬ß5; scripts/supabase-feature-store-bootstrap.sql for feature table.

================================================================================
PRIORITY (real-time data for paper trading algo)
================================================================================

üü¢ VINCEBINANCE HTTP 451 ‚Äì (1) DONE. (2) BACKLOG
   (1) DONE: binance.service.ts has logHttpWarn() with 5-min cooldown per endpoint,
   logs 451 with context "Unavailable For Legal Reasons ‚Äì check region/restrictions",
   and uses logger.debug for repeats. No more 451 flood on Eliza Cloud Warnings.
   (2) BACKLOG: Consider skipping Binance in signal aggregator when 451 persists
   (e.g. after N consecutive 451s) for graceful degradation.

üü¢ IMPROVE LOGS FOR ELIZA CLOUD (https://www.elizacloud.ai/) ‚Äì PARTIAL ‚úÖ
   Align with Eliza Cloud Container Logs / Metrics UX: filterable levels,
   structured context, less noise, high-signal summaries.
   - ‚úÖ Reduce INFO noise: Signal aggregator per-asset "N source(s) ‚Üí M factors"
     ‚Üí debug. Coinglass dashboard line ‚Üí debug. Hyperliquid OPTIONS PULSE
     (non-neutral) ‚Üí debug; CROSS-VENUE stays INFO only when arb opportunities.
     Paper trading: correlation/DVOL/regime/session/streak/ML sizing ‚Üí debug.
     Trade open/close, trigger hit, pause/resume, cascade/liquidations stay INFO.
   - Warnings: Prioritize actionable warnings (e.g. VinceBinance 451 above);
     avoid repetitive same-message warnings (use cooldown + debug for repeats).
   - Structure: Include consistent context (source tag, optional agentId/roomId
     when relevant) so Cloud log search/filter stays useful.
   - Optional: Periodically log a single "dashboard-style" summary (e.g. health
     of data sources, signal source counts) instead of many per-call lines.

üî¥ IMPROVE THE AMOUNT OF REAL-TIME DATA USED FOR THE PAPER TRADING ALGO
   We do not currently leverage all the data sources we already have available.
   - Ensure Binance, MarketRegime, News, Deribit, BinanceLiquidations, Sanbase,
     Hyperliquid, etc. actually contribute factors (see SIGNAL_SOURCES.md).
   - Confirm in logs: at startup [VINCE] üì° Signal sources available: N/8 (...);
     on each aggregation use LOG_LEVEL=debug to see VinceSignalAggregator per-asset contribution.
   - Use LOG_LEVEL=debug to see "tried but no contribution" for sources that ran
     but didn‚Äôt meet thresholds (e.g. taker ratio 0.7‚Äì1.3, neutral regime).
     ‚úÖ Extended: BinanceLiquidations, Sanbase, Hyperliquid now also reported in
     triedNoContribution when they run but don‚Äôt add a factor (see signalAggregator).
   - Populate MandoMinutes cache for News; consider relaxing or tuning thresholds
     so more sources contribute more often.

================================================================================
IN PROGRESS
================================================================================

üîÑ Paper trading bot needs more trades to tune Thompson Sampling weights
   ‚Üí Use VINCE_PAPER_AGGRESSIVE=true ($280 TP, 2:1 R:R, 40x, no cooldown) and VINCE_PAPER_ASSETS=BTC (focus BTC first) to get more trades and JSONL for ML.
üîÑ Feature store: 90+ trades available; ONNX training runs automatically (TRAIN_ONNX_WHEN_READY) or manually: python3 src/plugins/plugin-vince/scripts/train_models.py --data .elizadb/vince-paper-bot/features --output .elizadb/vince-paper-bot/models --min-samples 90. Install: pip3 install onnx onnxmltools.
üîÑ No improvement suggestions generated yet (needs more trading data)
üîÑ Increase real-time signal factors: get more sources contributing (see PRIORITY above)

================================================================================
MCP / ELIZA CLOUD ‚Äì LEVERAGE OPPORTUNITIES
================================================================================
(Ref: https://www.elizacloud.ai/ MCP catalog ‚Äì serverless, x402 micropayments, SSE/HTTP)

üìã ElizaOS Cloud MCP (v1.0.0 ‚Äì 20 tools) ‚Äì Platform
   Use for: credit management, AI generation, memory, conversations, agent interaction.
   - VINCE relevance: Offload heavy or rate-limited calls (e.g. when Binance 451);
     use Cloud memory/conversations for cross-session context; credit-based usage
     fits cost visibility in logs/deploy (see ‚ÄúImprove logs for Eliza Cloud‚Äù).
   - Action: Evaluate wiring plugin-vince to Cloud MCP for memory/credits when
     deploying to Eliza Cloud; document credit impact of signal aggregator + HL/Binance.

üìã Time & Date MCP (v2.0.0 ‚Äì 5 tools) ‚Äì Utilities
   Use for: current time, timezone conversion, date calculations.
   - VINCE relevance: Session filters (Asia/EU/US overlap) and day-of-week logic
     (Lifestyle, paper trading confidence/size) already use local time; MCP could
     provide canonical ‚Äúmarket open‚Äù / timezone for multi-region users and logs.
   - Action: Optional integration in VinceLifestyleService or signal aggregator
     for time-aware summaries; single source of truth for ‚Äúmarket session‚Äù in logs.

üìã Weather MCP (v2.0.0 ‚Äì 4 tools) ‚Äì Data
   Use for: real-time weather, 16-day forecast, location search (Open-Meteo).
   - VINCE relevance: Lifestyle action (dining, hotel, activities); day-of-week
     suggestions could be weather-aware (e.g. indoor vs outdoor by location).
   - Action: Backlog ‚Äì add Weather MCP as optional Lifestyle enrichment when
     user shares location or for curated ‚Äútoday‚Äôs vibe‚Äù in GM/Aloha.

üìã Crypto Price MCP (v2.0.0 ‚Äì 3 tools) ‚Äì Finance, Free
   Use for: live prices, market cap, trending coins (CoinGecko).
   - VINCE relevance: We already use CoinGecko (VinceCoinGeckoService), HIP-3,
     Hyperliquid. MCP could be fallback or secondary source for ‚Äútrending‚Äù and
     simple price checks without maintaining our own rate limits.
   - Action: Backlog ‚Äì consider Crypto Price MCP as optional fallback for
     meme/trending or for lightweight price context in actions (cost: free).

General: Adopting MCPs can reduce in-plugin API surface and centralize credits/cost
on Eliza Cloud; log MCP tool calls (tool name + credits if x402) for observability.

================================================================================
THINGS TO DO NEXT (high impact ‚Äì leverage data we have, not yet used in algo)
================================================================================

These use data we already collect (or can add with one small integration) but don‚Äôt yet feed into trading decisions. Doing them will have the most impact per unit effort.

1. **Use new market features in the trading algo (not just the feature store)**
   - We record bookImbalance, priceVsSma20, fundingDelta, dvol, rsi14. The signal aggregator and evaluateAndTrade don‚Äôt use them yet.
   - High impact: (a) In aggregator or evaluateAndTrade: skip or downweight LONG when bookImbalance < -0.2 (order book favors sellers); ditto SHORT when bookImbalance > 0.2. (b) Boost confidence when priceVsSma20 sign aligns with signal direction (trend confirmation). (c) Add a ‚Äúfunding reversal‚Äù factor when |fundingDelta| is large and opposite to current funding sign. (d) In risk manager or position sizing: cap size or reduce max leverage when dvol > threshold (e.g. 70) so we size down in high vol. See DATA_LEVERAGE.md; implement in signalAggregator.service.ts and/or vincePaperTrading.service.ts.

2. **Add NASDAQ 24h (and optionally macro/ETF) to news features**
   - Slots exist: news.nasdaqChange, news.etfFlowBtc, news.etfFlowEth, news.macroRiskEnvironment. Currently 0% populated.
   - High impact: Add one free or cheap macro/equity source (e.g. Yahoo Finance, Alpha Vantage, or HIP-3 index if we have NDX) and set news.nasdaqChange in collectNewsFeatures(). Optionally add ETF flow API or scrape so ML can use risk-on/risk-off. See DATA_LEVERAGE.md ‚ÄúData still 0%‚Äù.

3. **Use improvement report to tune aggregator weights**
   - training_metadata.json has feature_importances and suggested_signal_factors. When a factor we now populate (e.g. ‚ÄúOrder book imbalance‚Äù) drops from suggested_signal_factors, we know we‚Äôre good.
   - High impact: Periodically (or after each train) read suggested_signal_factors and feature_importances; log which sources/factors are top for signal quality; optionally align dynamicConfig source weights with importances so high-importance sources aren‚Äôt downweighted. See ALGO_ML_IMPROVEMENTS.md ¬ß ‚ÄúConsume improvement report‚Äù.

4. **Retrain and ship ONNX after new features have enough samples**
   - Once 90+ (ideally 200+) records have non-null fundingDelta, bookImbalance, priceVsSma20, run train_models.py; then copy ONNX + training_metadata.json into src/plugins/plugin-vince/models/ and deploy so Cloud uses the new models. Ensures ML actually uses the extra data we now collect.

5. **Optional: DVOL/regime in position cap**
   - We already have dvol and volatilityRegime. In position sizing or risk manager, reduce max leverage or cap position size when dvol > 70 (or volatilityRegime === 'high') so the algo explicitly uses the data for risk. Small code change, reuses existing fields.

================================================================================
NEXT / BACKLOG
================================================================================

üìã Migrate prod to Supabase Postgres (POSTGRES_URL); then plugin_vince.paper_bot_features
   lives in same DB as ElizaOS tables (agents, memories, entities, rooms). See FEATURE-STORE.md.
üü¢ Train ONNX when 90+ trades: task TRAIN_ONNX_WHEN_READY registered; runs on schedule (12h), max once per 24h; min-samples 90. On Cloud: Dockerfile installs Python ML deps; after training task uploads models to Supabase Storage (vince-ml-models) and calls ML service reloadModels(); on next deploy app downloads from bucket. Manual: pip3 install -r scripts/requirements.txt && python3 ‚Ä¶/train_models.py --data .elizadb/vince-paper-bot/features --output .elizadb/vince-paper-bot/models --min-samples 90. One-time: create bucket vince-ml-models in Supabase (DEPLOY.md).
üìã Add more NFT collections to floor tracking
üìã Implement ClawdBot integration for self-healing (see WHY.md)
üìã Add Telegram/Discord notifications for alerts
üìã Add more meme tokens to constants
üìã Implement position sizing based on Kelly Criterion ML model
üìã Add correlation-based position limits
üìã Implement trailing stop-loss logic

Product feedback ‚Üí backlog:
üìã NEWS: Build own news plugin + day report to reduce MandoMinutes dependency (likely X API ~$100/mo).
üìã MEMES: Fix bold styling in UI (quick fix; looks messy). Improve quality over time (not top priority).
üìã BOT: Polish BOT command‚Äîeasier on the eyes, consistent writing style with other actions.
üìã INTEL: Address redundancy with GM / Aloha (merge or differentiate).
üü¢ UPLOAD / knowledge: YouTube + article URLs use [Ikigai Labs summarize](https://github.com/IkigaiLabsETH/summarize) (fork of steipete/summarize) via bunx; transcript/summary saved to knowledge/<category>/. This improves our workflow to keep growing the knowledge folder from URLs and videos. Manual test: bun run scripts/test-summarize.ts (example: https://www.youtube.com/watch?v=wGucOorJlvk). Remaining: batch scripts for feeds, long PDFs; optional ClawdBot (Moltbot) for heavy ingestion.
üìã LIFESTYLE: More focus on curated local (hotel/restaurant/spa/health/fitness); may migrate to dedicated CLAWDBOT.
üìã NFT: Continue improving floor/tracking; solid MVP, "thin floor" gems from iconic collections still valued.

================================================================================
KNOWN ISSUES / LIMITATIONS
================================================================================

‚ö†Ô∏è XAI/Grok requires API key (not all users will have)
‚ö†Ô∏è Nansen limited to 100 credits/month
‚ö†Ô∏è Sanbase limited to 1K calls/month
‚ö†Ô∏è Paper bot circuit breakers not yet validated with real trading
‚ö†Ô∏è ONNX inference active when .onnx files present in models dir; install onnxmltools and run train_models.py to generate them (feature names f0,f1,‚Ä¶ applied at export for converter)
‚ö†Ô∏è Eliza Cloud deploy (vince2) timed out after 15 min; 15 credits were deducted
   (see DEPLOYMENT section below)

================================================================================
SUPABASE / STORAGE
================================================================================

We added this clarification so it‚Äôs recorded in progress.txt:

- **POSTGRES_URL (Supabase Postgres)** = main app database. ElizaOS (plugin-sql) uses it for conversation/message storage, agent memory, entities, rooms, relationships, tasks, cache, and knowledge embeddings. So Supabase is used for memory storage of conversations and all other runtime persistence. Required for persistent deploy; without it the app uses local PGLite.
- **SUPABASE_SERVICE_ROLE_KEY / SUPABASE_URL** = optional. Used for: (1) Feature store dual-write: paper-bot features upserted to table vince_paper_bot_features (create once: scripts/supabase-feature-store-bootstrap.sql); data persists across redeploys. (2) ML models on Cloud: Storage bucket vince-ml-models stores .onnx + training_metadata.json; training runs in container, app downloads latest on startup (no redeploy). Create bucket once: Dashboard ‚Üí Storage ‚Üí New bucket ‚Üí name: vince-ml-models (private). deploy-cloud.sh passes these from .env when set. See FEATURE-STORE.md and DEPLOY.md.

================================================================================
DEPLOYMENT (Eliza Cloud)
================================================================================

Current prod:
- Repo pushed to prod with Eliza Cloud; everything works fine.
- Still on PGLite (no POSTGRES_URL yet). Next step: migrate to Supabase Postgres
  so ElizaOS tables (agents, memories, entities, rooms, etc.) and
  plugin_vince.paper_bot_features live in the same Supabase DB. See FEATURE-STORE.md
  for how feature-store jsonl fits with ElizaOS auto-generated tables.

2026-02-02 ‚Äì vince2 deploy timeout (historical):
- Command: elizaos deploy --project-name vince2 (with ANTHROPIC, OPENAI, POSTGRES_URL)
- Credits: 15 deducted when container was created (before health check)
- Container created: 0983fab1-1756-4008-8f7c-c7592aa9c915
- Outcome: CLI reported "Deployment failed" ‚Äì timeout after 15 minutes waiting for
  container to pass health check (/health returning 200). Container may still exist
  or still be deploying.
- Dashboard: https://www.elizacloud.ai/dashboard/containers/0983fab1-1756-4008-8f7c-c7592aa9c915
- Next steps:
  1. Check status: elizaos containers list
  2. View logs: elizaos containers logs --project-name vince2 --tail 200
  3. Ensure app returns 200 OK at /health (required for deploy success)
  4. If deploy never became usable: contact Eliza Cloud support to request
     credit restoration for timed-out deployment (15 credits)

================================================================================
BRANDING, CHANNELS & X (TWITTER)
================================================================================

Frontend / branding (Eliza Cloud):
- The current frontend we have deployed through Eliza Cloud is fine for now but
  is very much NOT on brand with IKIGAI LABS and IKIGAI STUDIO.
- Intent: internal use only. Do NOT promote this deployment; it is for our team
  and community ops, not as a public-facing product.

Channel strategy ‚Äì ‚Äúwhere the community is‚Äù:
- We are super bullish on being where the users are (in our case, the community).
  Hence our focus order:
  1. DISCORD FIRST: Primary channel. Connect Discord servers for AI-powered
     automation (announcements, app updates, rich embeds, scheduled posts).
     Eliza Cloud Settings ‚Üí Discord Bot is the first integration we use.
  2. TELEGRAM SECOND: Connect Telegram bot for automation (channels, auto-reply
     in groups, welcome messages, /help and /about). Available in Eliza Cloud
     Settings ‚Üí Connections (Bot Token from @BotFather).
- Upcoming features (Eliza Cloud) we may or may not use:
  - Bluesky (Coming Soon) ‚Äì cross-platform automation.
  - LinkedIn (Coming Soon) ‚Äì professional content automation.
  - Meta Ads (Coming Soon) ‚Äì Facebook & Instagram campaigns.
  No commitment yet; evaluate when live.

X (Twitter) integration ‚Äì second thoughts:
- X integration feels like the most important channel from a reach perspective,
  but we have serious reservations due to backstory:
  - Most ElizaOS bots got banned on X.
  - The original ElizaOS (ai16z at the time) also got banned; they had to
    rebrand (including due to lawsuit) ‚Äì so the ecosystem has direct experience
    with X enforcement against agent/bot accounts.
- Outcome: We are not prioritizing X integration for now. Internal use and
  community focus (Discord, then Telegram) avoid that risk. Revisit X only if
  we have a clear, low-risk path (e.g. official partnerships or policy change).

================================================================================
SESSION NOTES
================================================================================

2026-02-03:
- Risk manager & sizing now treat exposure **by margin**, not by notional. `position.marginUsd`
  is stored on open/partial/restore; `getCurrentExposure()` sums margin; validateTrade() converts
  requested size to margin before enforcing both per-position and total caps. Aggressive preset
  (VINCE_PAPER_AGGRESSIVE=true) therefore allows multiple 40x HYPE positions so long as posted
  margin stays under 60% of portfolio instead of blocking at $40k notional.
- Feature store `collectMarketFeatures()` now fetches market context, Binance depth, DVOL, RSI,
  and ATR **in parallel** with a 6s timeout per source. One slow API no longer stalls the entire
  record, and latency shrank from ‚Äúsum of all awaits‚Äù to ‚Äúslowest call‚Äù.
- README trimmed to reflect reality: ALOHA day report (PERPS + OPTIONS vibe check) is the primary
  user-facing feature; every other action is treated as supporting/legacy until it advances the ML
  paper bot loop. Progress file updated accordingly.
- Knowledge ingestion loop doubled down: `VINCE_UPLOAD` now routes long-form sources through our
  summarize fork ([IkigaiLabsETH/summarize](https://github.com/IkigaiLabsETH/summarize)), so every
  morning upload (YouTube, podcast, PDF, article) lands in `knowledge/` with clean front‚Äëmatter +
  source URL. Daily habit: feed quality content ‚Üí run ALOHA informed by fresh research ‚Üí retrain ML.
- Added `VINCE_CHAT` action. Trigger with `chat: <question>` to get a free-form response that leans
  on `knowledge/` (top 3 matching files) and trench frameworks. Makes it easy to pressure-test ideas
  or recall playbooks without leaving the ALOHA/OPTIONS/PERPS workflow.
- MCP / Eliza Cloud: New section ‚ÄúMCP / ELIZA CLOUD ‚Äì LEVERAGE OPPORTUNITIES‚Äù in
  progress.txt with concrete suggestions: ElizaOS Cloud MCP (credits, memory,
  agent interaction), Time & Date (session/tz), Weather (Lifestyle), Crypto Price
  (fallback/trending). Each tied to plugin-vince use case and backlog action.
- Eliza Cloud logs: (1) VinceBinance HTTP 451 ‚Äì DONE (binance.service.ts: logHttpWarn
  with 5-min cooldown, 451 context, debug for repeats). (2) General log improvements
  for elizacloud.ai remain in PRIORITY (filterable levels, less noise, high-signal summaries).
- Signal sources: startup log [VINCE] üì° Signal sources available: N/8 (...); aggregator
  INFO logs list which sources contributed; DEBUG "tried but no contribution" for
  Binance, NewsSentiment, DeribitIVSkew, MarketRegime; extended to BinanceLiquidations,
  Sanbase, Hyperliquid when they run but don‚Äôt add a factor (signalAggregator). See SIGNAL_SOURCES.md.
- ONNX training when 90+ trades: getCompleteRecordCount() on feature store; TRAIN_ONNX_WHEN_READY task runs on schedule (12h), max once per 24h; spawns train_models.py --min-samples 90. On Cloud: Dockerfile has Python ML deps; task uploads models to Supabase Storage (vince-ml-models) and calls reloadModels(); ML service downloads from bucket on startup if local empty. One-time: create bucket vince-ml-models (DEPLOY.md). FEATURE-STORE.md updated.
- README (repo + plugin): Heart of VINCE, signal-source verification, improvement report.
- FEATURE-STORE.md: current prod state (Eliza Cloud, PGLite); ElizaOS tables vs feature
  store; jsonl lives in plugin_vince.paper_bot_features (same DB when Postgres), not
  in core ElizaOS tables. Optional Supabase table for ML queries.
- progress.txt: PRIORITY = improve real-time data for paper algo (leverage all sources);
  deployment note (prod works, still PGLite; next Supabase Postgres); NEXT = migrate
  to Supabase Postgres, then feature store in same DB as ElizaOS tables.
- Supabase: feature-store table (supabase-feature-store-bootstrap.sql), deploy-cloud.sh
  passes SUPABASE_* from .env; Storage bucket vince-ml-models for ML models (train on Cloud,
  download on startup). DEPLOY.md has one-time bucket instructions. See COMPLETED "ML on Eliza Cloud" and "SUPABASE / STORAGE".
- Product feedback: README "Action status (honest take)" added (OPTIONS/PERPS gold; NEWS
  MandoMinutes dependency; MEMES/TREADFI/LIFESTYLE/NFT/INTEL/BOT/UPLOAD). Backlog items
  added for news plugin, MEMES UI bold fix, BOT polish, INTEL redundancy, UPLOAD/knowledge,
  LIFESTYLE‚ÜíCLAWDBOT, NFT improvements.
- More trades for ML: Aggressive paper-trading preset (VINCE_PAPER_AGGRESSIVE=true ‚Üí $210
  take profit, max leverage 10) and single-asset focus (VINCE_PAPER_ASSETS=BTC ‚Üí bot only
  trades BTC) added. Goal: more closed trades ‚Üí more JSONL in .elizadb/vince-paper-bot/features
  ‚Üí faster path to 90+ records for ONNX training and better ML script testing. See
  FEATURE-STORE.md ‚ÄúAggressive paper trading‚Äù and ‚ÄúPaper bot: focus on one asset‚Äù; .env.example.
- UPLOAD + summarize: VINCE_UPLOAD uses [Ikigai Labs summarize](https://github.com/IkigaiLabsETH/summarize) (our fork of steipete/summarize) via bunx to keep improving the knowledge/ folder: (1) YouTube URLs ‚Üí transcript + summary (--youtube auto, 120s); (2) single article/PDF URLs ‚Üí summary (90s). Output is categorized and written to knowledge/<category>/ with source URL in frontmatter. Install: bun install -g @steipete/summarize (or use Ikigai fork from GitHub). Manual test: bun run scripts/test-summarize.ts (e.g. YouTube wGucOorJlvk; --extract validated 66k+ chars in ~3s). README and progress updated.
- Strong-signal confirming override: We need more training data, so more trades (and higher
  leverage where appropriate). Bot was correctly requiring 3 confirming sources for BTC, but
  was blocking strong signals (e.g. 65% strength, 67% confidence) that had only 2 agreeing
  sources. Added MIN_CONFIRMING_WHEN_STRONG=2 in paperTradingDefaults (SIGNAL_THRESHOLDS):
  when strength >= STRONG_STRENGTH (60) and confidence >= HIGH_CONFIDENCE (55), allow 2
  confirming signals instead of 3. Risk manager uses this in validateSignal(); HYPE still
  uses 2 always. Tuning this constant (or the strength/confidence bar) controls trade
  frequency vs. confluence. See vinceRiskManager.service.ts and paperTradingDefaults.ts.
- Aggressive mode ‚Üí 2 confirming: When VINCE_PAPER_AGGRESSIVE=true, syncFromDynamicConfig()
  now sets minConfirmingSignals=2 (vs 3) so 2 agreeing sources are enough to trade. Fixes
  "Only 2 confirming signals, need 3" blocks when CoinGlass + Binance agree but a third
  source (TopTraders, Sanbase, News, etc.) doesn't. .env.example and progress.txt updated.
- Paper trading aggressive preset ‚Äì R:R and risk tuning: SL was ATR-based only, often giving
  poor R:R (0.4:1‚Äì0.5:1). We now set SL from target R:R so max loss = TP / TARGET_RR. Constants
  in paperTradingDefaults: TARGET_RR_AGGRESSIVE=2, TAKE_PROFIT_USD_AGGRESSIVE=280, MIN_SL_PCT_
  AGGRESSIVE=0.35, MAX_SL_PCT_AGGRESSIVE=1.5, MIN_SL_ATR_MULTIPLIER_AGGRESSIVE=0.5. Logic in
  vincePaperTrading.service.ts openTrade(): (1) Aggressive single-TP: SL% = (TP/2)/sizeUsd*100
  clamped to [0.35%, 1.5%]; (2) volatility floor: if ATR available, SL% = max(SL%, 0.5√óATR) then
  cap at 1.5% so we never put the stop inside normal chop; (3) banner shows R:R quality label
  (Good/OK/Weak/Poor) and TP as [$280]. Result: 2:1 R:R, $280 TP, $140 risk; fewer trades
  needed for daily target; no cooldown after loss in aggressive (AGGRESSIVE_RISK_LIMITS.cooldownAfterLossMs=0).
  Trade-opened banner was also cleaned up (fixed-width lines, section labels, spacing).
- Fetch performance (important): (1) Coinglass: all HTTP fetches use AbortSignal.timeout(10s); refreshData() fetches all assets + fear/greed in parallel; fetchCoinGlassData runs OI, funding, Binance L/S in parallel per asset; fetchFreeData runs price, funding, L/S, OI history in one Promise.all. (2) Signal aggregator: added SOURCE_FETCH_TIMEOUT_MS=12s and withTimeout(ms, label, promise) helper; phase-1 async sources (Binance getIntelligence, Deribit getIVSurface, MarketData getEnrichedContext, Sanbase getOnChainContext, Hyperliquid getOptionsPulse + getCrossVenueFunding, Deribit getComprehensiveData + getVolatilityIndex) are fetched in a single Promise.all with per-call timeout; sections 3‚Äì10 use these pre-fetched results instead of sequential awaits. Phase-2 calls (getTakerVolume, getRSIAdjustment, getOpenWindowInfo) wrapped in withTimeout. getAllSignals() now uses Promise.all(assets.map(getSignal)) so multi-asset aggregation is parallel. Result:   aggregation time bounded by slowest source (~12s max) instead of sum of many sequential calls.
- Scripts and ONNX: (1) Switched ONNX export from skl2onnx to onnxmltools (XGBoost not supported by skl2onnx). (2) Export failed until booster feature names set to f0, f1, ‚Ä¶ before convert_xgboost (onnxmltools requires that pattern). (3) All four .onnx models now export when pip3 install onnx onnxmltools. (4) Docs and log messages use pip3 (Mac). (5) generate_synthetic_features.py: --append to extend existing JSONL (timestamps continue), optional larger --count; train_models loads all synthetic_*.jsonl in --data dir.    (6) test_train_models.py: 6 tests pass (generate‚Üítrain, learning baseline, insufficient data, SL label, multi-asset). (7) requirements.txt: onnxmltools>=1.16.0, no skl2onnx; install note: pip3 install -r requirements.txt.
- progress.txt: This file updated to reflect completed ONNX export (onnxmltools, f0/f1 feature names), synthetic data (--append, --count), and test_train_models.py (6 tests). ML inference service uses session.run({ input: tensor }) and results.output; ONNX models exported by train_models use default onnxmltools input/output names (compatible).
- Eliza Cloud logs: INFO noise reduced. Signal aggregator (per-asset contribution), Coinglass dashboard, Hyperliquid OPTIONS PULSE ‚Üí debug. Paper trading sizing details (correlation, DVOL, regime, session, streak, ML) ‚Üí debug. CROSS-VENUE arb stays INFO when arb opportunities. .env.example: tip added for VINCE_PAPER_AGGRESSIVE + VINCE_PAPER_ASSETS=BTC to get more trades for ML.
- ML flow: (1) Similarity "avoid" ‚Üí hard filter in evaluateAndTrade (skip trade with log). (2) Bandit: store contributingSources on position.metadata at open (from signal.sourceBreakdown); on close call weightBandit.recordOutcome({ sources, profitable, pnlPct }) so source weights learn from actual trade outcomes. (3) ALGO_ML_IMPROVEMENTS.md: #5 and #6 marked done; added "Further ML flow improvements" (labels, calibration, retrain triggers, feature alignment, A/B shadow).
- ML active on Cloud: see "ML on Eliza Cloud" subsection below.
- Leverage more data points: (1) Funding 8h delta: per-asset funding history cache in feature store; delta = current ‚àí rate from ~8h ago. (2) Price vs SMA20: rolling window of last 20 prices per asset. (3) Order book: Binance futures depth (BTC/ETH/SOL/HYPE) ‚Üí bookImbalance and bidAskSpread. (4) News: sentimentScore (¬±confidence) and sentimentDirection from getOverallSentiment; hasActiveRiskEvents/highestRiskSeverity from getActiveRiskEvents. (5) Signal avgSentiment from keyword scan over signal.factors; train script uses signal.avgSentiment as signal_avg_sentiment. DATA_LEVERAGE.md and ALGO_ML_IMPROVEMENTS.md updated.

2026-02-02:
- Created progress.txt
- Finetuned START.md to be VINCE/ElizaOS specific
- Verified documentation stack (WHAT, WHY, HOW, CLAUDE, START)
- Plugin has 27 services, 20 actions, 2 providers, 1 evaluator
- ML layer collecting features, awaiting sufficient data for training
- Eliza Cloud deploy (vince2) timed out; 15 credits deducted; documented above
- Documented Supabase usage in progress.txt: POSTGRES_URL = main app DB (conversations, memory, entities, rooms, embeddings). Optional SUPABASE_SERVICE_ROLE_KEY = feature store (vince_paper_bot_features) for ML only. See FEATURE-STORE.md for feature-store setup.
